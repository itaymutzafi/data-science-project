{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project – Main Notebook\n",
    "### Tel Aviv University – Data Science Workshop\n",
    "\n",
    "This notebook presents the full workflow of our project. The final topic will be decided and approved by the teaching staff during the upcoming week.\n",
    "\n",
    "All analysis steps are structured according to the course guidelines:\n",
    "- Business understanding\n",
    "- Data exploration\n",
    "- Data preparation\n",
    "- Feature engineering\n",
    "- Modeling\n",
    "- Evaluation\n",
    "- Interpretation of results\n",
    "\n",
    "_All placeholder sections will be filled once the dataset and task are finalized._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Overview\n",
    "### 1.1 Topic (to be finalized)\n",
    "<Insert description of the chosen topic here>\n",
    "\n",
    "### 1.2 Motivation\n",
    "<Insert motivation according to domain (finance / neuroscience / other)>\n",
    "\n",
    "### 1.3 Research Questions\n",
    "- RQ1: <Insert>\n",
    "- RQ2: <Insert>\n",
    "- RQ3: <Insert>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports and Environment Setup\n",
    "This section imports all required libraries. Additional libraries may be added later based on project needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data_loader import load_csv\n",
    "from src.preprocessing import basic_cleaning, split_X_y\n",
    "from src.utils import configure_pandas_display\n",
    "\n",
    "configure_pandas_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading\n",
    "\n",
    "Once the final dataset is approved, place the raw files inside `data/raw/`.\n",
    "\n",
    "_Example placeholder below:_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder: example load once dataset exists\n",
    "# df_raw = load_csv(\"<file_name>.csv\", folder=\"raw\")\n",
    "# df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initial Data Exploration (EDA)\n",
    "\n",
    "This phase follows the course guidelines:\n",
    "- Getting a \"feel\" for the data\n",
    "- Understanding distribution, correlations, missing values, outliers\n",
    "- Checking if integration of additional datasets is required\n",
    "\n",
    "_All placeholders will be filled after loading the approved dataset._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for EDA summaries\n",
    "# df_raw.info()\n",
    "# df_raw.describe()\n",
    "# df_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Visual Exploration\n",
    "Visualization guidelines from the course: keep it simple, appropriate scale, labeled axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example placeholder (to implement once data exists)\n",
    "# sns.pairplot(df_raw)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning and Preparation\n",
    "\n",
    "Based on the course lectures, this includes handling:\n",
    "- Missing values (MCAR / MAR / MNAR)\n",
    "- Outliers\n",
    "- Normalization\n",
    "- Integration of multiple data sources if necessary\n",
    "\n",
    "All steps will be expanded once the dataset is chosen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for cleaning\n",
    "# df_clean = basic_cleaning(df_raw)\n",
    "# df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "According to course tutorials:\n",
    "- Transformations\n",
    "- Binning / discretization\n",
    "- Encoding categorical variables\n",
    "- PCA or dimensionality reduction (if needed)\n",
    "- Domain-based features (e.g., daily return, volatility, or temporal descriptors)\n",
    "\n",
    "_This section will be expanded once the dataset structure is known._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for engineered features\n",
    "# df_features = df_clean.copy()\n",
    "# df_features[\"new_feature\"] = <definition>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modeling\n",
    "\n",
    "Once the task is finalized (classification / regression / ranking / time-series prediction), this section will include:\n",
    "- Train-test split\n",
    "- Baseline model\n",
    "- Alternative models\n",
    "- Hyperparameter tuning\n",
    "- Cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for modeling workflow\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# X, y = split_X_y(df_features, label_column=\"<label>\")\n",
    "# X_train, X_test, y_train, y_test = create_train_test(X, y)\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation\n",
    "\n",
    "Based on the guidelines:\n",
    "- Accuracy, F1, precision/recall (for classification)\n",
    "- MSE/MAE/R² (for regression)\n",
    "- ROC/AUC\n",
    "- Cross-validation\n",
    "\n",
    "_Exact metrics will follow the approved task._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for evaluation\n",
    "# from src.evaluation import evaluate_basic\n",
    "# metrics = evaluate_basic(model, X_test, y_test)\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interpretation and Insights\n",
    "\n",
    "This section will include:\n",
    "- Feature importance\n",
    "- Model explainability (SHAP / LIME)\n",
    "- Comparison to baseline\n",
    "- Practical significance\n",
    "\n",
    "To be completed after first modeling iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions and Next Steps\n",
    "This final section will summarize:\n",
    "- What we discovered\n",
    "- Outstanding challenges\n",
    "- Next steps for fine-tuning the model or analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
